{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d557888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType, StructType, StructField, FloatType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer,  OneHotEncoder,  StandardScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.regression import LinearRegression,  RandomForestRegressor, GBTRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeffee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "spark = SparkSession.builder.appName('regression').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8193a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.format('csv').option('header', 'true').option('inferSchema','true').option('numPartitions',100).load('data_cleaned.csv')\n",
    "data = data.sample(fraction=0.005)\n",
    "data = data.repartition(200)                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e0cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                        (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+------+---+-----+----------+----------+----------+-------+-----+\n",
      "|     lat|     long| operator|status|net|speed|satellites|precission|  activity|hour_24|label|\n",
      "+--------+---------+---------+------+---+-----+----------+----------+----------+-------+-----+\n",
      "|41.69279|   1.7891| movistar|     2| 4G|  0.1|       6.0|       9.0|     STILL|     12|  4.0|\n",
      "|41.39408|  2.16954|   orange|     2| 3G|  1.1|       5.0|      29.0|   ON_FOOT|     14|  7.0|\n",
      "|41.39213|  2.16522|   others|     2| 4G|  7.3|       7.0|      21.0|IN_VEHICLE|     13| 10.0|\n",
      "|41.64385|  2.73346|pepephone|     2| 4G| 43.9|       1.0|       7.0|IN_VEHICLE|     12| 29.0|\n",
      "|41.44764|  1.97855| movistar|     2| 4G|117.8|       8.0|       3.0|IN_VEHICLE|     14| 22.0|\n",
      "|41.46967|  2.08247| movistar|     2| 4G|  0.6|       4.0|       9.0|     STILL|     12| 14.0|\n",
      "|41.17764|   1.5134|   orange|     2| 4G|  0.0|       8.0|      12.0|IN_VEHICLE|     11| 13.0|\n",
      "|41.62855|  0.83421|pepephone|     2| 2G| 47.3|       8.0|      19.0|IN_VEHICLE|     12|  8.0|\n",
      "|41.65159|  2.77806|   orange|     2| 3G|  0.1|       3.0|     128.0|     STILL|     12|  2.0|\n",
      "|41.75562|  0.91181| movistar|     2| 2G| 89.7|       1.0|      27.0|IN_VEHICLE|      1|  9.0|\n",
      "|41.46132|  1.89996|   others|     2| 3G|107.8|       7.0|      64.0|IN_VEHICLE|     10|  0.0|\n",
      "|41.27329|  1.99102| movistar|     2| 2G| 15.1|       5.0|      12.0|IN_VEHICLE|      9| 20.0|\n",
      "|41.18733|  1.56988|   others|     0| 3G|  0.0|       0.0|      48.0|     STILL|     11|  6.0|\n",
      "|41.69778|  2.43192|   orange|     2| 4G|  2.3|       5.0|      31.0|   ON_FOOT|     10| 23.0|\n",
      "|41.42955|   2.1447| movistar|     2| 4G| 62.0|       5.0|      24.0|IN_VEHICLE|     18| 12.0|\n",
      "|42.12889|  2.20131| movistar|     2| 3G| 95.1|       7.0|       3.0|IN_VEHICLE|     18|  3.0|\n",
      "|41.36249|  2.13155|   others|     2| 4G|  2.9|       6.0|      19.0|   ON_FOOT|     11|  6.0|\n",
      "|26.57604|-82.00619|   others|     2| 4G|  0.7|       6.0|      28.0|   ON_FOOT|     20| 28.0|\n",
      "|42.62328|  1.12383|   orange|     2| 3G|  1.4|       3.0|      25.0|   ON_FOOT|      0| 22.0|\n",
      "|41.41972|  1.17686| movistar|     2| 2G| 67.7|       6.0|      16.0|IN_VEHICLE|      1| 15.0|\n",
      "+--------+---------+---------+------+---+-----+----------+----------+----------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:====================================================>     (9 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##数据预处理 status类型转换为string， 将signal 改成 label（float）， 去掉provider\n",
    "\n",
    "data_processed = data.withColumn('status', data.status.cast(StringType())).withColumn(\n",
    "    'label', data.signal.cast(FloatType())).drop('signal','provider')\n",
    "data_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c31fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集分割 \n",
    "train_df, val_df, test_df =data_processed.randomSplit([0.7,0.2, 0.1], seed=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a98f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## one hot 编码\n",
    "categoricalCols = [field for (field, dataType) in data_processed.dtypes if dataType == \"string\"]\n",
    "inputOutputCols = [x+\"index\" for x in categoricalCols]\n",
    "oheOutputCols = [x+\"OHE\" for x in categoricalCols]\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
    "                              outputCols=inputOutputCols,\n",
    "                              handleInvalid=\"skip\")\n",
    "oheEncoder = OneHotEncoder(inputCols=inputOutputCols, outputCols=oheOutputCols)\n",
    "numeric_cols = [field for (field, dataType) in data_processed.dtypes if ((dataType != \"string\") & (field !='label'))]\n",
    "assembled_numeric = VectorAssembler(inputCols=numeric_cols, outputCol=\"features_numeric\")\n",
    "scaler = StandardScaler(inputCol=\"features_numeric\", outputCol=\"features_scaled\", withStd=True, withMean=True)\n",
    "assembled_inputs = oheOutputCols+[\"features_scaled\"]\n",
    "\n",
    "\n",
    "##将数据集组合成 feature向量\n",
    "vecAssembler = VectorAssembler(inputCols=assembled_inputs, outputCol='features')\n",
    "\n",
    "##选择loss func\n",
    "evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb67add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:33:33 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:33:35 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:33:38 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:33:43 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:33:49 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:33:56 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:========>                                             (30 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.239s][warning][gc,alloc] Executor task launch worker for task 42.0 in stage 68.0 (TID 6503): Retried waiting for GCLocker too often allocating 256 words\n",
      "[53.243s][warning][gc,alloc] Executor task launch worker for task 37.0 in stage 68.0 (TID 6498): Retried waiting for GCLocker too often allocating 256 words\n",
      "[53.243s][warning][gc,alloc] Executor task launch worker for task 41.0 in stage 68.0 (TID 6502): Retried waiting for GCLocker too often allocating 256 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:=============>                                        (50 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.898s][warning][gc,alloc] Executor task launch worker for task 56.0 in stage 68.0 (TID 6517): Retried waiting for GCLocker too often allocating 256 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:34:04 WARN DAGScheduler: Broadcasting large task binary with size 1103.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:===========>                                             (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numtrees=10, maxdepth=15, rmse_train=5.472850625117252, rmse_test=7.12934530119325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##validationsplit manually\n",
    "numTrees = [10]\n",
    "maxDepth = [15]\n",
    "\n",
    "\n",
    "for i in numTrees:\n",
    "    for j in maxDepth:\n",
    "            rf = RandomForestRegressor(featuresCol='features', labelCol='label',numTrees=i, maxDepth=j)\n",
    "            pipeline_onetime = Pipeline(stages=[stringIndexer, oheEncoder, assembled_numeric,scaler, vecAssembler, rf])\n",
    "            onetime_model = pipeline_onetime.fit(train_df)\n",
    "            rmse_train = evaluator.evaluate(onetime_model.transform(train_df), {evaluator.metricName: \"rmse\"})\n",
    "            rmse_test = evaluator.evaluate(onetime_model.transform(test_df), {evaluator.metricName: \"rmse\"})\n",
    "            print(\"numtrees={}, maxdepth={}, rmse_train={}, rmse_test={}\".format(i, j, rmse_train, rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9a123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 247:===========>                                            (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:34:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/27 01:34:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/04/27 01:34:28 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"features\",labelCol='label')\n",
    "##选择loss func\n",
    "evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction')\n",
    "\n",
    "##定义超参数的范围\n",
    "param_grid_2 = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "##利用验证集调参\n",
    "tvs_2 = TrainValidationSplit(estimator=gbt,\n",
    "                           estimatorParamMaps=param_grid_2,\n",
    "                           evaluator=RegressionEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "pipeline = Pipeline(stages=[stringIndexer, oheEncoder, assembled_numeric, scaler, vecAssembler, tvs_2])\n",
    "pipelinemodel = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6fb26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|        prediction|label|\n",
      "+------------------+-----+\n",
      "|20.471043158654336| 11.0|\n",
      "|13.296157091955775| 23.0|\n",
      "|16.107365659520738| 18.0|\n",
      "|14.074648207214432| 31.0|\n",
      "|16.690338789337943| 13.0|\n",
      "|14.060406284522578| 14.0|\n",
      "| 17.05004079715291| 11.0|\n",
      "|12.773843104368236| 15.0|\n",
      "|14.081243551577533|  6.0|\n",
      "|12.794045136475807|  7.0|\n",
      "|14.062280461717844| 14.0|\n",
      "|13.719220776091511| 29.0|\n",
      "|12.325897662578592| 18.0|\n",
      "|   12.304454135598| 22.0|\n",
      "|12.708322698054028| 31.0|\n",
      "| 11.37528746041952|  6.0|\n",
      "|11.736420617619002| 14.0|\n",
      "|13.200346369429164|  3.0|\n",
      "|10.578434527889755| 14.0|\n",
      "|12.493982918852206| 15.0|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.967196907747071"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##预测\n",
    "pipelinemodel.transform(test_df).select('prediction','label').show()\n",
    "rmse = evaluator.evaluate(pipelinemodel.transform(train_df), {evaluator.metricName: \"rmse\"})\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a16aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.053013952526691"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## evaluation\n",
    "rmse = evaluator.evaluate(pipelinemodel.transform(test_df), {evaluator.metricName: \"rmse\"})\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994a3496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\\ncheckpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\\nfeatureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto' (default: all)\\nfeaturesCol: features column name. (default: features, current: features)\\nimpurity: Criterion used for information gain calculation (case-insensitive). Supported options: variance (default: variance)\\nlabelCol: label column name. (default: label, current: label)\\nleafCol: Leaf indices column name. Predicted leaf index of each instance in each tree by preorder. (default: )\\nlossType: Loss function which GBT tries to minimize (case-insensitive). Supported options: squared, absolute (default: squared)\\nmaxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32)\\nmaxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30]. (default: 5)\\nmaxIter: max number of iterations (>= 0). (default: 20, current: 20)\\nmaxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size. (default: 256)\\nminInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\\nminInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\\nminWeightFractionPerNode: Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5). (default: 0.0)\\npredictionCol: prediction column name. (default: prediction)\\nseed: random seed. (default: -6682481135904123338)\\nstepSize: Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator. (default: 0.1)\\nsubsamplingRate: Fraction of the training data used for learning each decision tree, in range (0, 1]. (default: 1.0)\\nvalidationIndicatorCol: name of the column that indicates whether each row is for training or for validation. False indicates training; true indicates validation. (undefined)\\nvalidationTol: Threshold for stopping early when fit with validation is used. If the error rate on the validation input changes by less than the validationTol, then learning will stop early (before `maxIter`). This parameter is ignored when fit without validation is used. (default: 0.01)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelinemodel.stages[5].bestModel.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ebd5e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##lr\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "param_grid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.3, 0.4]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.7, 0.8]) \\\n",
    "    .build()\n",
    "tvs_lr = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=param_grid_lr,\n",
    "                           evaluator=RegressionEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "pipeline_lr = Pipeline(stages=[stringIndexer, oheEncoder, assembled_numeric, scaler, vecAssembler, tvs_lr])\n",
    "lr_model = pipeline_lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a60602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.272473256051158"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(lr_model.transform(train_df), {evaluator.metricName: \"rmse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4874d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.237576035795086"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(lr_model.transform(test_df), {evaluator.metricName: \"rmse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "975e4e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###combing three columns to do the stacking\n",
    "lr = LinearRegression(maxIter=100, regParam=0.002, elasticNetParam=0.0, predictionCol='predict_lr')\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='label', numTrees=13, maxDepth=12, predictionCol='predict_rf')\n",
    "gbt = GBTRegressor(featuresCol=\"features\",labelCol='label', predictionCol='predict_gbt')\n",
    "pipeline_final = Pipeline(stages=[stringIndexer, oheEncoder, assembled_numeric, scaler, vecAssembler, lr, rf, gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b55bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:35:42 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:35:53 WARN DAGScheduler: Broadcasting large task binary with size 1101.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:35:55 WARN DAGScheduler: Broadcasting large task binary with size 1796.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:35:58 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:36:02 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline_model = pipeline_final.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556e98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pipeline_model.transform(train_df).select('label', 'predict_lr','predict_rf','predict_gbt') \\\n",
    "                        .withColumn('predict',(F.col('predict_lr')+F.col('predict_rf')+F.col('predict_gbt'))/3)\n",
    "rmse_lr = RegressionEvaluator(labelCol=\"label\", predictionCol='predict_lr', metricName=\"rmse\")\n",
    "rmse_rf = RegressionEvaluator(labelCol=\"label\", predictionCol='predict_rf', metricName=\"rmse\")\n",
    "rmse_gbt = RegressionEvaluator(labelCol=\"label\", predictionCol='predict_gbt', metricName=\"rmse\")\n",
    "rmse = RegressionEvaluator(labelCol=\"label\", predictionCol='predict', metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38c96455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.250222554446609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.289106691600019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.967196907747071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1333:=====>                                                 (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.773012934831043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(rmse_lr.evaluate(data_new))\n",
    "print(rmse_rf.evaluate(data_new))\n",
    "print(rmse_gbt.evaluate(data_new))\n",
    "print(rmse.evaluate(data_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f91a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.219358038273961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.029265703599833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.053013952526691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1349:===========>                                           (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.041891452438378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_fitted = pipeline_model.transform(test_df).select('label', 'predict_lr','predict_rf','predict_gbt') \\\n",
    "                        .withColumn('predict',(F.col('predict_lr')+F.col('predict_rf')+F.col('predict_gbt'))/3)\n",
    "print(rmse_lr.evaluate(test_fitted))\n",
    "print(rmse_rf.evaluate(test_fitted))\n",
    "print(rmse_gbt.evaluate(test_fitted))\n",
    "print(rmse.evaluate(test_fitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7716304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###combing three columns to do the stacking\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, predictionCol='predict_lr')\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='label', numTrees=33, maxDepth=10, predictionCol='predict_rf')\n",
    "gbt = GBTRegressor(featuresCol=\"features\",labelCol='label', predictionCol='predict_gbt')\n",
    "vecAssembler_agg = VectorAssembler(inputCols=['predict_gbt','predict_rf','predict_lr'], outputCol='features_agg')\n",
    "lr_stack = LinearRegression(featuresCol='features_agg',labelCol='label' ,predictionCol='predict_stack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7c751af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:37:00 WARN DAGScheduler: Broadcasting large task binary with size 1443.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:37:03 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:37:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1722:=====>                                                 (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:37:38 WARN Instrumentation: [e0da3657] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline_stack = Pipeline(stages=[stringIndexer, oheEncoder, assembled_numeric,\n",
    "                                  scaler, vecAssembler,lr, rf, gbt,vecAssembler_agg, lr_stack])\n",
    "stack_model = pipeline_stack.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb140249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.2907663134658405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_stack = RegressionEvaluator(labelCol=\"label\", predictionCol='predict_stack', metricName=\"rmse\")\n",
    "rmse_stack.evaluate(stack_model.transform(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a35e96bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.275834604985077"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_stack = RegressionEvaluator(labelCol=\"label\", predictionCol='predict_stack', metricName=\"rmse\")\n",
    "rmse_stack.evaluate(stack_model.transform(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fadccfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1739:>                                                     (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:37:48 WARN Instrumentation: [876088b7] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline_stack_v2 =  Pipeline(stages=[vecAssembler_agg, lr_stack])\n",
    "test_fitted = pipeline_model.transform(val_df).select('label', 'predict_lr','predict_rf','predict_gbt')\n",
    "stack_model_v2 = pipeline_stack_v2.fit(test_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80988380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.00977262961062"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_stack.evaluate(stack_model_v2.transform(pipeline_model.transform(test_df).select('label', 'predict_lr','predict_rf','predict_gbt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "197464cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.173006674726298"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_stack.evaluate(stack_model_v2.transform(test_fitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "144918d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:38:13 WARN DAGScheduler: Broadcasting large task binary with size 1443.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:38:15 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:38:20 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1812:=======================================>           (154 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[319.488s][warning][gc,alloc] Executor task launch worker for task 162.0 in stage 1812.0 (TID 214663): Retried waiting for GCLocker too often allocating 256 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1812:==========================================>        (167 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320.007s][warning][gc,alloc] Executor task launch worker for task 182.0 in stage 1812.0 (TID 214683): Retried waiting for GCLocker too often allocating 34420 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2124:=====>                                                 (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/27 01:38:52 WARN Instrumentation: [c344f0b0] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline_final = Pipeline(stages=[stringIndexer, oheEncoder, assembled_numeric, scaler, vecAssembler, lr, rf, gbt])\n",
    "pipeline_model = pipeline_final.fit(train_df)\n",
    "pipeline_stack_v2 =  Pipeline(stages=[vecAssembler_agg, lr_stack])\n",
    "stack_model_v2 = pipeline_stack_v2.fit(pipeline_model.transform(val_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
